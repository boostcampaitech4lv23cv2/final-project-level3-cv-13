{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 및 딕셔너리를 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sashimi_category = {'Olive_flounder_sashimi' : 0,\n",
    "                    'Korea_rockfish_sashimi' : 1,\n",
    "                    'Red_seabream_sashimi' : 2,\n",
    "                    'Brown_croaker_sashimi' : 3,\n",
    "                    'Red_drum_sashimi' : 4,\n",
    "                    'Tilapia_sashimi' : 5,\n",
    "                    'Salmon_sashimi' : 6,\n",
    "                    'Tuna_sashimi' : 7,\n",
    "                    'Japanese_amberjack_sashimi' : 8\n",
    "                   }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuda 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f'Currently using {device}...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model pth 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.efficientnet = timm.create_model('efficientnet_b4', pretrained = True, num_classes = num_classes, drop_rate=0.5, act_layer = nn.ReLU)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n",
    "\n",
    "file_path = './sashimi_EfficientNetB4_best_epoch41_0.8336.pth'\n",
    "model = TempModel(num_classes =9)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(file_path))\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계산을 위해 Feature map 과 class weight를 가져오자 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hook을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making hook\n",
    "activation=None\n",
    "class_weight = None\n",
    "\n",
    "def hook_4_fm(model,input,output):\n",
    "    global activation\n",
    "    activation =output.clone().detach().requires_grad_(True)\n",
    "\n",
    "def hook_4_clf_w(model,input,output):\n",
    "    global class_weight\n",
    "    class_weight = model.weight\n",
    "\n",
    "model.efficientnet.conv_head.register_forward_hook(hook_4_fm)\n",
    "model.efficientnet.classifier.register_forward_hook(hook_4_clf_w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "class transforms_1:\n",
    "    def __init__(self, resize) -> None:\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(*resize, cv2.INTER_LINEAR),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        return self.transforms(image=image)\n",
    "\n",
    "transform=A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "trans_resize = A.Compose([\n",
    "    A.Resize(384,384)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "dataset_dir = os.path.join(current_path,\"test_data\")\n",
    "\n",
    "data_list = os.listdir(dataset_dir)\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = data_list[0]\n",
    "\n",
    "#추후 비교를 위해 따로 저장\n",
    "origin_image = np.array(cv2.imread(os.path.join(dataset_dir,image_name)))\n",
    "origin_image = trans_resize(image=origin_image)['image']\n",
    "\n",
    "#학습을 위한 데이터\n",
    "image = transform(image=origin_image)['image']\n",
    "image = image.unsqueeze(0)\n",
    "image = image.to(device, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image)\n",
    "preds = torch.argmax(output, dim=-1)\n",
    "tmp = activation.squeeze(axis = 0)\n",
    "print(tmp.shape)\n",
    "print(class_weight.shape)\n",
    "label_weight = class_weight[preds[0]]\n",
    "print(label_weight.shape)\n",
    "label_weight = label_weight.unsqueeze(-1).unsqueeze(-1)\n",
    "print(label_weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = torch.squeeze(tmp)* label_weight\n",
    "cam = torch.sum(cam,axis = 0)\n",
    "cam = cam.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origin = origin_img.detach().cpu().numpy()\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "final_cam = cv2.resize(cam, dsize=(384, 384), interpolation= cv2.INTER_CUBIC)\n",
    "\n",
    "img_rgb = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,40))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"CAM + Image\")\n",
    "\n",
    "#plt.imshow(origin_image)\n",
    "plt.imshow(img_rgb)\n",
    "plt.imshow(final_cam,cmap = 'jet' ,alpha=0.6)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Origin\")\n",
    "#plt.imshow(origin_image)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "plt.title(\"CAM\")\n",
    "im =plt.imshow(final_cam, cmap = 'jet')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size = \"5%\", pad = 0.05)\n",
    "plt.colorbar(im, cax= cax)\n",
    "print(\"정답 : \", image_name)\n",
    "keys = sashimi_category.keys()\n",
    "key_lst = list(keys)\n",
    "print(\"예측 : \",key_lst[preds[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "dataset_dir = os.path.join(current_path,\"test_data\")\n",
    "\n",
    "data_list = os.listdir(dataset_dir)\n",
    "\n",
    "\n",
    "def CAM (image_name):\n",
    "    #추후 비교를 위해 따로 저장\n",
    "    origin_image = np.array(cv2.imread(os.path.join(dataset_dir,image_name)))\n",
    "    origin_image = trans_resize(image=origin_image)['image']\n",
    "\n",
    "    #학습을 위한 데이터\n",
    "    image = transform(image=origin_image)['image']\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.to(device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    #inference 진행\n",
    "    output = model(image)\n",
    "    preds = torch.argmax(output, dim=-1)\n",
    "\n",
    "    #feature map 뽑아내기\n",
    "    tmp = activation.squeeze(axis = 0)\n",
    "\n",
    "    #class weight 뽑아내기\n",
    "    label_weight = class_weight[preds[0]]\n",
    "\n",
    "    #연산을 위한 차원 변환\n",
    "    label_weight = label_weight.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    #cam 만들기\n",
    "    cam = torch.squeeze(tmp)* label_weight\n",
    "    cam = torch.sum(cam,axis = 0)\n",
    "    cam = cam.detach().cpu().numpy()\n",
    "\n",
    "    # 사진을 겹쳐보기 위한 resize 해주기\n",
    "    final_cam = cv2.resize(cam, dsize=(384, 384), interpolation= cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    img_rgb = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #시각화\n",
    "    plt.figure(figsize=(20,40))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"CAM + Image\")\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.imshow(final_cam,cmap = 'jet' ,alpha=0.6)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Origin\")\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    ax = plt.subplot(1,3,3)\n",
    "    plt.title(\"CAM\")\n",
    "    im =plt.imshow(final_cam, cmap = 'jet')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size = \"5%\", pad = 0.05)\n",
    "    plt.colorbar(im, cax= cax)\n",
    "    print(\"파일이름 : \", image_name)\n",
    "    keys = sashimi_category.keys()\n",
    "    key_lst = list(keys)\n",
    "    print(\"예측 : \",str(key_lst[preds[0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래의 코드를 연속 실행해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기화\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    CAM(data_list[index])\n",
    "    index +=1\n",
    "except IndexError:\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
